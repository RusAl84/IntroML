{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RusAl84/IntroML/blob/master/8_1_%D0%9E%D0%B1%D1%83%D1%87%D0%B0%D0%B5%D0%BC%D1%8B%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_%D0%B8_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnUDQWvlwGwa"
      },
      "source": [
        "# Задачи машинного обучения, понятие модели, обучения. \n",
        "## Введение. Параметрические модели\n",
        "Люди всегда хотели облегчить свою жизнь, предсказать, когда произойдет какое-либо событие и как оно будет происходить чтобы подготовиться к нему. С древних времен люди умеют предсказывать, например, солнечные затмения. Но как можно что-то предсказать?\n",
        "\n",
        "Дело в том, что все, что происходит в нашем мире, подчиняется некоторым **законам**. Планеты летают в космосе не произвольно, как им вздумается, а подчиняясь строгим правилам взаимодействия с Солнцем, другими планетами и другими телами. Такие законы постоянны и если их узнать (открыть), то можно, используя такой закон, и предсказать поведение планет и любых других объектов (а кто открыл законы движения планет?).\n",
        "\n",
        "Закон это набор правил и взаимоотношений между объектами, выраженный по-разному: словами, картинками или математическими формулами. Математика оказалась очень удобна для выражения законов и дала сильный толчок к познанию новых законов, выводам из них, предсказанию. \n",
        "\n",
        "Но одной математики мало, математика может только помогать нам описывать правила взаимодействия между величинами, но сами эти величины нам тоже должны быть известны. Их нужно **измерить**. Это задача физики, науки о нашем мире, как измерить то или иное явление, процесс, величину. \n",
        "\n",
        "Когда все необходимое измерено, мы можем построить **модель** изучаемого процесса или явления. Модель это совокупность законов, правил, описывающих поведение изучаемого процесса, явления, объекта. Модель может быть, например, физической. Все вы делали бумажные самолетики, которые являются моделью настоящего самолета, не полной, не точной, но позволяющей понять принципы полета. Но чаще всего модель представляется в виде математических формул, ее так и называют **математическая модель**. Для разных целей могут потребоваться разные модели одного и того же объекта, они могут быть проще и сложней, менее или более точные, описывать разные стороны поведения объекта. Представляя модели в виде формул, уравнений, можно их решить и тем самым предсказать поведение нашего исследуемого объекта. Точность предсказания зависит, в первую очередь, от точности модели, насколько хорошо та описывает поведение объекта. Но также зависит и от точности решения уравнений модели. \n",
        "\n",
        "Разных объектов много, не хотелось бы для каждого из них придумывать отдельную модель. Поведение многих объектов похоже, надо для них использовать похожие модели. Например, тела массой 1 кг, 2 кг или 3 кг, при падении подчиняются одним и тем же законам, но двигаются по-разному. Это можно учесть если ввести в уравнение, описывающее движение массивных тел, некоторый **параметр** – массу этого тела. И изменять только параметр, не изменяя форму самого уравнения. Модели с параметрами называются **параметрическими моделями** и удобны для описания множества схожих объектов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ-M-OKpwGwd"
      },
      "source": [
        "## Подход \"Черного ящика\" и Обучение\n",
        "Часто бывает так, что для изучаемого объекта физические законы еще не открыты или они слишком сложны (ну-ка напишите формулу как глаз распознает изображения). Но если мы можем измерять поведение объекта, то можно попробовать создать модель на основе измерений, не вникая в физические законы, которые такое поведение обеспечивают.\n",
        "\n",
        "Мы работаем в подходе \"черного ящика\", когда не знаем внутреннее устройство изучаемого объекта, но можем измерять его реакцию на различные воздействия, и строить модель такого объекта.\n",
        "\n",
        "![img](https://drive.google.com/uc?id=1GS0SaGo6i9K1cOkYru0Ws5tnSw61H_uo)\n",
        "\n",
        "\n",
        "Если бы мы могли сделать модель с параметрами, такую, что при изменении параметров описываемое ей поведение изменялось бы в широких пределах (в идеале давало бы любое поведение), то могли бы сказать себе: *а давайте подбирать параметры модели так, чтобы в конце концов поведение модели совпало с измеренным поведением объекта*. \n",
        "\n",
        "Пример такого подбора показан на рисунке, здесь красная линия – измеренное поведение объекта, синяя – поведение модели при разных параметрах.\n",
        "\n",
        " ![img](https://drive.google.com/uc?id=1OBOZWdyonBnQwAmAR0hCq0WnaSGuOm5X)\n",
        "\n",
        "Если модель в принципе способна описать поведение объекта, то подбором параметров мы сможем получить такое же поведение модели, осталось только найти подходящие параметры. Каждый раз, подбирая параметры, мы говорили модели, плохо или хорошо она описывает поведение объекта, такой процесс называют **обучением**. Когда модель создается в компьютере, т.е. вычислительной машине, такой процесс называют **машинным обучением**. Мы обучили модель вести себя также, как и объект, обучение это подбор параметров модели для достижения заданной цели. А какая цель? Цель – уменьшить **ошибку** модели, отклонение ее поведения от заданного поведения объекта. Идеал – нулевая ошибка – редко достижим, поэтому стремятся уменьшить ошибку до какой-то приемлемой небольшой величины. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Тестирование\n",
        "Однако цель обучения не просто запомнить поведение объекта на измеренных данных, это просто, но в том, чтобы эта модель могла давать правдоподобные результаты и на других примерах данных, на которых ее не обучали. Например, вы решаете задания из учебника по математике, но должны научиться решать не только эти конкретные задания, но и все похожие на них. Также и модель, должна научиться моделировать объект не только на данных о поведении объекта на которых ее обучали, но и на других.\n",
        "\n",
        "Чтобы узнать, а как модель себя ведет на других данных, не на тех на которых ее обучали (данные, на которых обучали, называют обучающими), такую модель **тестируют**, а данные на которых ее тестируют, называют тестовыми. Смотрят на тестовых данных поведение модели и сравнивают с поведением объекта для тестовых данных. Можно посчитать и ошибку тестирования. Важно, чтобы тестовые данные действительно отличались от обучающих. Способность модели давать приемлемые результаты на тестовых данных называют **обобщающей способностью**, и именно повышение ее является целью обучения. \n"
      ],
      "metadata": {
        "id": "Dw-hi37KRiBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Гиперпараметры\n",
        "Надо различать **параметры модели** (обучаемые параметры) – те числа, которые изменяются в процессе обучения – и другие числа, которые описывают модель, но которые не меняются методом обучения, а задаются нами (размер модели, число ее элементов и др.). Последние называют **гиперпараметрами** или метапараметрами.\n",
        "\n",
        "В силу сложности моделируемых объектов, наличия шумов, модели машинного обучения дают *приближенные* результаты, всегда присутствует ошибка и цель обучения в том, чтобы сделать эту ошибку маленькой и приемлемой.\n",
        "\n",
        "Еще раз, для обучения модели: \n",
        "* 1) выбрана или создана модель с параметрами;\n",
        "* 2) есть какие-то указания как модель должна себя вести в определенных ситуациях, измеренное поведение объекта (обучающие данные);\n",
        "* 3) есть оценка того, как хорошо (или плохо) модель описывает поведение объекта на обучающих данных – ошибка обучения модели;\n",
        "* 4) подбираем параметры чтобы уменьшить ошибку на обучающих данных.\n",
        "* 5) тестируем модель на тестовых данных.\n",
        "\n",
        "Если все хорошо, ошибки обучения и тестирования маленькие и приемлемые, то мы, скорей всего (но не гарантировано) получили хорошую модель, которую потом можем использовать "
      ],
      "metadata": {
        "id": "X0cavhToRlWf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2wQ8SI4wGwe"
      },
      "source": [
        "## Данные\n",
        "Но встречается огромное количество проблем, связанных с обучением. Некоторые из них описаны ниже.\n",
        "\n",
        "Модели с обучением очень **требовательны к данным**. Данные, на которых модель обучается и тестируется:\n",
        "\n",
        "1) должны быть *разнообразны*, бесполезно обучать на одинаковых данных, даже если их много. Ничему новому модель не научится.\n",
        "\n",
        "2) должны быть *непротиворечивы*, если вам учитель говорит один раз, что дважды два четыре, а другой раз, что пять, то чему вы сможете научиться? Также и модель. Когда данных много некоторые противоречия (ошибки) допустимы, модель с хорошей обобщающей способностью справится с этим, также, как и вы, если учитель девять раз вам повторял что дважды два четыре, а на десятый сказал, что пять, то, я надеюсь, вы не забудете таблицу умножения сразу же. Но таких противоречий должно быть немного.\n",
        "\n",
        "3) должны быть *релевантны* задаче, действительно полностью описывать реальные моделируемые объекты. При измерениях неизбежны ошибки, если они маленькие не страшно, измеренные данные примерно описывают объект, но если большие – то беда, никак не узнать конкретное измеренное данное это ошибка или действительное описание объекта.\n",
        "\n",
        "4) *тестовые данные должны отличаться от обучающих*, иначе тест бесполезен.\n",
        "\n",
        "Это понятные, но трудно выполнимые требования. И только для тех областей, где можно собрать требуемые данные, модели с обучением будут хорошо работать. К счастью, таких областей становится все больше и больше. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOgIwZuiwGwh"
      },
      "source": [
        "## Признаки\n",
        "Входными данными в модели машинного обучения могут быть любые типы данных, изображения, звуки, тексты, таблицы и т.п., переведенные в числовые массивы.\n",
        "\n",
        "Часто бывает так, что нет необходимости использовать сами эти данные, а можно использовать их **признаки**. Признаки бывают разнообразными, например, если мы хотим распознать лицо человека, то можем использовать само изображение лица. Наша модель должна научится понимать из изображения, лицо ли это. Но можно использовать другие описания этого лица, например померить заранее есть ли на изображении глаза, нос, рот, и др., где они расположены, и использовать только эту информацию, без самого изображения. И в этом случае модель тоже распознает лицо, но на основе не самого изображения, а признаков лица в этом изображении: наличие носа, рта, глаз и др. Изображение – большой массив, перечисление же признаков – меньший, значит модель может работать быстрее и, возможно, точнее. Но будет ли модель точнее зависит от качества признаков, насколько точно и полно они описывают распознаваемый объект.\n",
        "\n",
        "К примеру, глаза, рот, нос есть и у животных, поэтому это лишь косвенные признаки человека. Но если вдруг среди признаков попался признак с названием «наличие паспорта Гражданина Российской Федерации», то тут однозначно – есть паспорт, значит человек. Это прямой признак человека, специфичный для него. Модель может быть очень простой, проверить признак паспорта, есть – значит человек. Но вот отсутствие паспорта не означает что перед нами не человек. \n",
        "\n",
        "Выбор признаков — это очень сложный вопрос и часто интуитивный. Никто заранее не скажет вам какие признаки хорошие, а какие нет. Например, раньше мы преобразовывали звук в спектр, характеристики спектра — это тоже какие-то признаки звука и судя по качеству работы моделей, довольно хороший, но это вовсе не значит, что единственный или самый лучший.\n",
        "\n",
        "Разные признаки можно извлекать из данных и использовать в моделях машинного обучения, например, довольно часто используется матрица расстояний между объектами, когда каждый объект описывается расстояниями до всех остальных объектов обучающих данных. Каждый может придумать свои признаки для решения поставленной задачи. Есть способы автоматического извлечения признаков, про них мы как-нибудь отдельно поговорим. В любом случае признаки это наборы чисел, которые описывают наши данные и важно, чтобы они описывали данные как можно точней. Данные являются признаками самих себя, поэтому во многих моделях признаки не извлекаются специально, а извлекаются автоматически, без участия человека, к счастью современные модели это позволяют. Но всегда нужно помнить, что от качества признаков зависит качество модели, поэтому нужно искать все лучшие и лучшие признаки. \n",
        "\n",
        "Признаки могут представляться по-разному: в виде бинарных чисел есть-нет (присутствует-отсутствует), в виде целых чисел, в виде дробных чисел и т.д.; массивов (векторов, матриц, многомерных) таких чисел, действительных или комплексных. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aI2oC5bwGwi"
      },
      "source": [
        "## Виды обучения\n",
        "В зависимости от того, какие именно данные нам доступны и какие цели преследует обучение, можно выделить несколько видов обучения:\n",
        "\n",
        "* А) **Обучение с учителем**. Здесь данные представляются в виде пар примеров входов в модель и *требуемых выходов* (такие выходы называют также «указания учителя») из нее для этих входов. Например, при распознавании изображений примерами входов являются сами изображение чего-то, а требуемыми выходами – название того, что на изображении изображено. Модель учится на этих парах, пытаясь подобрать свои параметры так, чтобы ее выходы совпали или были близки к требуемым. Это наиболее распространенный вид обучения. Поясню, что «учитель» — это не человек, а процесс, который смог собрать эти пары данных (это может быть и человек, и компьютер и др.). \n",
        "* Б) **Обучение без учителя** или самообучение. Бывает и так, что требуемые выходы модели неизвестны, но есть примеры входов. В этом случае модель может попытаться установить взаимосвязи между элементами входов, выделить каки-то общие черты. Для этого должен быть задан критерий такого выделения (явно или неявно). Например, есть набор звукозаписей с разным жанром музыки, но мы незнаем ни названий этих жанров, ни какой жанр у каждой из звукозаписей. Нужно распределить эти звукозаписи по «похожим» группам, надеясь, что это окажутся жанры. Действительно, звукозаписи одного жанра похожи друг на друга, а разных – отличаются, даже не зная названий вы легко отличите хэвиметалл от музыки для маленьких детей. Здесь вам никто не говорил, что вот эта звукозапись — это рок, а эта – классика. Вы поняли это только сравнивая между собой звукозаписи. Также и модель можно обучить выявлять схожие и различные черты данных. Это тоже популярный вид обучения, но более сложный, часто используется не сам по себе, а в дополнение к обучению с учителем.\n",
        "* В) **Обучение с подкреплением**. Бывает, что «учитель» сам не знает, как именно должно быть, но понимает какие действия обучаемого хорошие и могут позволить достичь цели, а какие плохие. Вот пытаетесь вы на автомобиле доехать до булочной, а учитель не знает где она. Но зато он знает, что ехать по дороге – хорошо, сворачивать в забор – плохо. Он может штрафовать или награждать вас за действия. При такой информации тоже можно научиться и достигнуть цели, получая штрафы за съезд с дороги и поощрения за езду по ней, вы рано или поздно, проехав по многим дорогам, булочную найдете. Конечно, у вас нет так много времени и возможностей врезаться в забор, а у компьютера есть. Перебирая возможные варианты действий модель в компьютере будет получать штрафы или награды за действия и может научиться, какие же действия приводят к наибольшей суммарной награде. Обычно такую модель называют «агент», с систему наград и штрафов «внешней средой», которая симулирует какую-то настоящую среду. Такой вид обучения отличается и от обучения с учителем, поскольку здесь не говорится как именно должно быть, и от обучения без учителя, поскольку все-таки есть некоторая информация учителя в виде наград и штрафов от среды. Такой подход используют, например, для создания ботов для компьютерных игр.\n",
        "\n",
        "Можно сочетать разные виды обучения между собой, например, обучение с учителем для данных у которых есть указания учителя и самообучение для данных у которых их нет."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qEal6MwwGwi"
      },
      "source": [
        "## Способы организации обучения\n",
        "В зависимости от того, как часто поступают данные и как часто нужен результат, все перечисленные выше виды обучения могут выполняться несколькими способами: \n",
        "- Динамическое или **онлайн обучение**. Как только данное поступило, необходимо сразу же, так быстро как позволяет компьютер, выдавать результат для него и доучивать модель (т.е. изменять параметры ее) для этого данного. Для большинства моделей с этим видом обучения важен порядок поступления данных: те же самые данные для той же самой модели, но представленные в другом порядке, могут привести к другому результату. Как пример, пусть модель имеет какое-то состояние (параметр, внутренне число) s (изначально 0), каждый раз прибавляет к нему вход и на выходе возвращает произведение этого числа s и входа. Если входы были (1, 2, 3), то состояние будет s= (0 изначально, 1=0+1, 3=1+2) результат (0=0 * 1, 2=1 * 2, 9=3 * 3). Если входы были в другом порядке (3, 2, 1), то состояние s будет s= (0 изначально, 3=0+3, 5=3+2) и результат будет другой (0=0 * 3, 6=3 * 2, 5=5 * 1). Онлайн обучение хорошо тем, что оно быстрее, но обычно менее точное, и зависит от порядка поступления данных.\n",
        "- Отложенное или **оффлайн обучение**. Здесь параметры модели изменяются только после того, как для всех данных будут рассчитаны выходы. Обычно здесь порядок поступления данных не важен. Пусть модель работает также, как в предыдущем примере, но состояние s не изменяется, пока все данные не будут рассчитаны, изначально s=0, так что все выходы будут равны 0, для любого порядка поступления входов, и только после того как все выходы будут рассчитаны, s изменится на 6=0+1+2+3.  Оффлайн обучение хорошо тем, что обычно не зависит от порядка поступления данных и более точное, но зато медленнее. \n",
        "- Компромиссный вариант между онлайн и оффлайн обучением это **пакетное обучение**. Данные разбиваются на маленькие группы (пакеты, или по-английски batch), и параметры модели изменяются только после расчета пакета целиком. Изменяя размер пакета, сколько в него входит данных, мы можем балансировать между онлайн (размер пакета = 1) и оффлайн (размер пакета = количеству всех данных) обучением. Сегодня, пожалуй, это самый распространенный вариант организации обучения. Кстати, раз он похож на онлайн обучение, то результат может зависеть от порядка поступления пакетов, чтобы как-то с этим бороться пакеты часто перемешивают случайно.\n",
        "- Вариант, когда модель может сама выбирать порядок поступления данных, называют **активное обучение**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0FlMUGNwGwj"
      },
      "source": [
        "## Задачи машинного обучения\n",
        "Множество задач можно решить с помощью машинного обучения, вот только некоторые из них:\n",
        "\n",
        "1) **Классификация**. Имея набор примеров входов и список классов (названий, меток, номеров) нужно распределить примеры входов по этим классам. Например, отличить мальчиков от девочек по фотографии. Список классов состоит из двух названий «мальчик» или «девочка», примеры входов – фотографии. Список возможных классов известен заранее и не бесконечен. Модель, которая решает такую задачу называется классификатором. Классификация может быть двухклассовой или бинарной, когда классов всего два, или многоклассовой, когда классов больше (одноклассовая классификация бессмыслена). Часто вводят специальный класс «не класс» (шум), к которому относят все, что не смогли отнести к другим классам. Обычно решается с помощью моделей с обучением с учителем.\n",
        "\n",
        "2) **Кластеризация**. Имея только примеры входов, разбить их на группы (кластеры) так, чтобы внутри кластеров примеры были чем-то похожи, а примеры из разных кластеров чем-то отличались между собой. Обычно решается с помощью моделей с обучением без учителя, пример с звукозаписями оттуда как раз о кластеризации. Часто число кластеров неизвестно заранее, и даже их названия неизвестны. Также вводят специальный кластер «не кластер» (шум), в который группируют все, что не попало в другие кластеры.\n",
        "\n",
        "3) **Регрессия**. Имея набор примеров входов и соответствующих им выходов научиться выдавать выходы для других примеров входов с той же взаимосвязью входов и выходов. Отличается от классификации тем, что в классификации выход это класс (номер, название или другое его представление), т.е. дискретная величина, а в регрессии выход непрерывен (не дискретен). Классификация – частный случай регрессии, т.к. дискретную величину можно представить вариантом непрерывной. Пример: зная температуру на улице, определить температуру в доме. Многие другие задачи сводятся к регрессии.\n",
        "\n",
        "4) **Прогнозирование**. Зная, как изменялась какая-то величина до определенного времени, узнать, как она будет изменяться после. Например, узнать температуру на улице на завтра, зная, как она изменялась раньше. Обычно сводится к задаче регрессии.\n",
        "\n",
        "5) **Оптимизация**. Имея примеры данных и некоторую функцию, заданную на этих данных, найти такие данные, для которых функция принимает оптимальное (минимальное или максимальное) значение. Например, есть набор шариков разного размера и материала, зададим вес как функцию от размера и плотности материала шарика (ну-ка быстро написали такую функцию), нужно найти шарик с максимальным весом. Обучение — это, по сути, оптимизация функции ошибки модели. Поэтому, так или иначе, все (ну почти все) задачи сводятся к оптимизации некоторой функции. Оптимизация это или минимизация или максимизация. Здесь и всегда мы не будем различать мини- и максимизацию, потому что это одинаковые задачи. Если мы умеем минимизировать функцию, меняем у нее знак и теперь мы умеем ее максимизировать. Проверьте.\n",
        "\n",
        "Другие задачи, число их велико, но они так или иначе сводятся к перечисленным выше: \n",
        "- **ранжирование**. Отличается от регрессии или классификации тем, что выходы надо получить сразу на множестве примеров, после чего отсортировать их по значениям выходов. Встречается, например, в поисковых системах типа Google. \n",
        "- **сокращение размерности**. Входы часто являются объектами большой размерности (вектора, матрицы, массивы), но все ли элементы входов одинаково важны? Зачастую можно отбросить или преобразовать входы так, что их размерность будет меньше, но при этом наиболее важные черты данных сохранятся и не будут потеряны. Как пример, нарисовать стомерный массив трудно, но можно найти такую его двумерную проекцию, чтобы было видно как можно лучше структуру данных в нем. Нарисовать двумерный массив гораздо проще.\n",
        "- и другие…."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMYaDbbwwGwl"
      },
      "source": [
        "## Функционалы ошибки и метрики\n",
        "Как мы помним, обучение – это подбор параметров модели с целью уменьшения функции ошибки (по-английски loss). Сами функции ошибки разнообразны, зависят от задачи, которую вы решаете, модели, которую используете, данных, на которых проходит обучение. Самой простой и распространенной функцией ошибки L, пожалуй, является функция квадрата расстояния между вектором Y выхода модели и указаний учителя T (требуемого выхода) на обучающих данных X: \\\\(L=(Y(X)-T(X))^2\\\\). Если примеров данных несколько (для пакетного или оффлайн обучения), то берут среднее значение L между примерами. Любые другие расстояния, или, как их называют математики, *меры*, тоже могут использоваться в функциях ошибки (например модуль разности, а не квадрат, это так называемая L1 мера). Функция ошибки может быть и очень сложной, например, в обучении с подкреплением, она определяется симуляцией внешней среды. Одну и ту же модель можно использовать с разными функциями ошибки, получая разные результаты. Часто в функцию ошибки добавляют ограничения для модели, например, чтобы ее параметры были не очень велики. \n",
        "\n",
        "## Цена ошибки\n",
        "Разные ошибки могут иметь разную цену, например если мы распознаем наличие мины через показание миноискателя, то для ошибки принять мину за постороннюю железку цена очень велика – жизнь сапера, а для ошибки принять постороннюю железку за мину цена гораздо меньше – несколько лишних минут поработать лопатой. Такие цены ошибок можно учесть заранее в функции ошибки, приписав веса членам, отвечающим за определенную ошибку. Конечно и результат будет другой.\n",
        "\n",
        "## Метрики\n",
        "Вообще, сложилась такая ситуация, что для подавляющего большинства моделей, за редким исключением, мы оптимизируем вовсе не то, что хотели. Скажем для задач классификации, функция ошибки обычно это средний квадрат расстояния между векторами выхода и указаний учителя. Но цель-то уменьшить число неправильно классифицированных примеров. В идеале, когда ошибка 0, то и число неправильно классифицированных примеров тоже 0, но в остальном эти функции – средний квадрат расстояния и число ошибок – разные. Дело в том, что к функции ошибки, которая будет использоваться для оптимизации параметров, предъявляют жесткие требования, например, чтобы она была дифференцируема. Число ошибок — это не дифференцируемая функция, а квадрат расстояния – дифференцируемая. \n",
        "\n",
        "Назовем то, что мы хотели бы оптимизировать **метрикой** (по-английски metrics). Для одной задачи можно посчитать множество разных метрик. Именно метрики описывают качество решения задачи, а функция ошибки — это косвенное средство достижения заданных метрик. Но бывает и так, что можно обойтись без отдельной функции ошибки, используя только метрику, это возможно для методов оптимизации, которые не требуют дифференцированности функций."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFFEddJgwGwl"
      },
      "source": [
        "## Некоторые метрики для задач классификации \n",
        "Давайте посмотрим на бинарную классификацию, когда у нас всего два класса (например, «мина» и «не мина»). Основной метрикой для такой задачи является матрица потерь (confusion matrix), у которой одно измерение отвечает за классы, посчитанные моделью, второе за истинные классы из данных, а в клеточках указывается количество соответствующих (или доля) примеров. Возможно всего четыре ситуации:\n",
        "- была мина и модель приняла ее за мину, это верное распознавание, обозначим как TP.\n",
        "- не было мины и модель так и ответила, это тоже верное распознавание, обозначим как TN.\n",
        "- была мина, но модель сказала, что это не мина, это ошибка, обозначим как FP.\n",
        "- не было мины, но модель сказала, что была, это тоже ошибка, обозначим как FN.\n",
        "\n",
        "![img](https://drive.google.com/uc?id=1co-LCVaJVYRAkYVbhNsJ3tyoZCMwS7-E)\n",
        "\n",
        "Матрица несет в себе всю информацию о качестве модели, в идеале элементы вне главной диагонали (ошибки) равны нулю. Но матрица сложна для понимания человеком, поэтому на основе этой матрицы считают множество других метрик:\n",
        "\n",
        "![img](https://drive.google.com/uc?id=1tD2eYLhJLOMQDFloQOUg-MM0kUXNIEhG)\n",
        "\n",
        "![img](https://drive.google.com/uc?id=1l66kwu7ntgciRH9EPKtO3rRdJ0-a47fM)\n",
        "\n",
        "Часто в модели можно легко изменять какой-то гиперпараметр, в результате чего будут меняться ответы и метрики (обычно это порог для отнесения к классу), удобно строить кривую ROC (Receiving operation curve) у которой по одной оси отложено FPR, а по другой TPR при изменении этого параметра. Площадь под этой кривой, AUC  (Area Under Curve), тоже является метрикой. Можно придумать и другие метрики. Для многоклассовой классификации похожие усредненные метрики могут быть использованы. Также, как и в функцию ошибки в метрики можно вводить веса (цену) отдельным типам ошибок.\n",
        " \n",
        "\n",
        " ![img](https://drive.google.com/uc?id=1tCyA4Bj9ZYzhDxaNu9lpT16UvXP_NprL)\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3xzrSeYwGwl"
      },
      "source": [
        "## Модели\n",
        "\n",
        "Придумано большое количество моделей машинного обучения, простых и сложных, точных и не очень, легко вычисляемых и требующих огромных вычислительных мощностей. Оставшаяся часть курса будет посвящена некоторым моделям. Поиск лучшей модели — это сложный эксперимент, перебирают разные модели, разные варианты моделей, а все это требует времени и средств. И никто, никто, не скажет вам как правильно, потому что однозначного правильного ответа вовсе нет. Нельзя заранее сказать какая модель будет лучше или хуже, бывает так, что простая модель окажется лучше сложной или наоборот. В первую очередь это зависит от данных, на которых она обучается. Надо пробовать разные варианты, читать и исследовать решения похожих задач, смотреть, а как их решали ранее, что можно улучшить. Не думайте, что пройдя курс, вы вдруг сможете решить любую задачу, так не бывает. Мы подобрали простые примеры, которые уже многократно успешно решались, но есть хорошая пословица *«Дьявол кроется в деталях»*. Поменяй условия и модель перестанет работать, например, обучили модель распознавать автомобили, но раз, другое освещение, дождь, туман, и все, модель больше не работает. Обучили модель на обучающих и тестовых данных «идеально», но данные оказались не релевантны реальности, не описывают ее, и «идеальная» модель, на которую вы затратили кучу сил и времени, стала бесполезной. Обучение моделей это тяжелый труд, часто требуется интуиция и удача, но у тех кто пойдет по этому пути, кто не будет пасовать перед трудностями (*ааааа, у меня ничего не работает!*) и проводить много исследований, читать литературу – все получится. \n",
        "\n",
        "К нашему счастью, множество моделей уже разработано, реализовано в программных библиотеках, и бывает так, что достаточно нажать пару кнопочек, вызвать несколько функций, и все работает. Мало просто решить задачу, нужно понимать, как вы ее решили. Мы не просим вас запоминать сложные математические формулы и понятия, это придет потом, в институте, но понимать суть происходящего, принципы работы моделей – необходимо.\n",
        "\n",
        "Кратко перечислим модели, с которыми мы познакомимся в этом курсе, а подробнее поговорим про них позже, не пугайтесь иногда странных названий этих моделей, и помните, что это математические модели.\n",
        "- деревья решений и случайный лес;\n",
        "- наивная байесовская классификация;\n",
        "- линейная регрессия и метод наименьших квадратов;\n",
        "- логистическая регрессия;\n",
        "- метод опорных векторов;\n",
        "- ансамблевые методы: бустинг, беггинг, конкретно xgboost, catboost;\n",
        "- метод к-средних Kmeans;\n",
        "- метод к ближайших соседей KNN;\n",
        "- метод главных компонент PCA;\n",
        "- методы обучения метрик;\n",
        "- нейронные сети (основы).\n"
      ]
    }
  ]
}